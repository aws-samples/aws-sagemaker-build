{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SageBuild Tutorial\n",
    "\n",
    "This notebook will walk you through on how to use Sagebuild to build and deploy custom models on-demand or in response to events. We will reuse the code from the \"scikit_bring_your_own\" example notebook.\n",
    "\n",
    "## Helpfull Links\n",
    "* [Blog Post]() to see the details of how SageBuild works. \n",
    "* [See here](/notebooks/sample-notebooks/advanced_functionality/scikit_bring_your_own/scikit_bring_your_own.ipynb) for details of how to write Dockerfiles for your own algorithms.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Setup](#SetUp)\n",
    "2. [Deploy](#Deploy)\n",
    "3. [Wait](#Wait)\n",
    "4. [Use](#Use)\n",
    "5. [Conclusion](#Conclusion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SetUp <a name=\"SetUp\"></a>\n",
    "The following sets up the packages and variables we need. Note, the region and StackName variables have been filled in for you by the cloudformation template."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "from subprocess import check_output as run\n",
    "from subprocess import STDOUT\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from io import StringIO\n",
    "\n",
    "cf = boto3.client('cloudformation')\n",
    "sns = boto3.client('sns')\n",
    "step = boto3.client('stepfunctions')\n",
    "s3 = boto3.resource('s3')\n",
    "ssm = boto3.client('ssm')\n",
    "sagemaker = boto3.client('sagemaker-runtime')\n",
    "Lambda=boto3.client('lambda')\n",
    "\n",
    "region='${AWS::Region}'\n",
    "StackName='${AWS::StackName}'\n",
    "data='../sample-notebooks/advanced_functionality/scikit_bring_your_own/data/iris.csv'\n",
    "\n",
    "#Get outputs from build stack\n",
    "result=cf.describe_stacks(\n",
    "    StackName=StackName\n",
    ")\n",
    "#Put Outputs in a dict for easy use\n",
    "outputs={}\n",
    "for output in result['Stacks'][0]['Outputs']:\n",
    "    outputs[output['OutputKey']]=output['OutputValue']\n",
    "print(\"Stack Outputs\")\n",
    "print(json.dumps(outputs,indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The follow shell commands will configure git to be able to access AWS CodeCommit and clone down the example repo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#configure git to be able to access CodeCommit,uses SageMaker Instance's role for permissions.\n",
    "!git config --global credential.helper '!aws codecommit credential-helper $@'\n",
    "!git config --global credential.UseHttpPath true\n",
    "\n",
    "#clone down our example code\n",
    "!git clone https://github.com/aws-samples/aws-sagemaker-build.git\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## configuration\n",
    "\n",
    "Both the training-job and endpoint have various configuration parameters. The build generates those parameters by calling two lambda functions with the current build state. The CloudFormation template initializes these lambdas with responable defaults but if you want to edit these, use different instances types, add more data channels, or use hyper parameters then you will need to change/update the function code.\n",
    "\n",
    "- The Dockfile path lambdas output the path to the directory containing the Dockerfile for the images in the code repository\n",
    "\n",
    "- The training lambda must output an object that matchs the input params for the create training job function in AWS js sdk. see [here](https://docs.aws.amazon.com/AWSJavaScriptSDK/latest/AWS/SageMaker.html#createTrainingJob-property)\n",
    "\n",
    "- The endpoint lambda must output an object that matchs the input params for the create endpoint config function in AWS js sdk. see [here](createEndpointConfig)\n",
    "\n",
    "\n",
    "\n",
    "you can look at the code in the lambda functions in the console to get an idea of were to start.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import io\n",
    "#creates a lambda deployment zip of python script\n",
    "def getZip(name):\n",
    "    buffer=io.BytesIO()\n",
    "    with zipfile.ZipFile(buffer, mode='w') as zf:\n",
    "        zf.write(f\"./aws-sagemaker-build/docker-images/config/{name}.py\",arcname=\"index.py\") \n",
    "    return buffer.getvalue()\n",
    "\n",
    "#creates a lambda deployment zip of a string\n",
    "def zipString(text):\n",
    "    buffer=io.BytesIO()\n",
    "    info = zipfile.ZipInfo(\"index.py\")\n",
    "    info.external_attr=0o777 << 16 \n",
    "    with zipfile.ZipFile(buffer, mode='w') as zf:\n",
    "        zf.writestr(info,text) \n",
    "    return buffer.getvalue()\n",
    "\n",
    "#Update lambda with code in a string\n",
    "Lambda.update_function_code(\n",
    "    FunctionName=outputs['TrainingDockerfilePathLambda'],\n",
    "    ZipFile=zipString(\"\"\"\n",
    "def handler(event,context):\n",
    "    return \"docker-images/train\"    \n",
    "\"\"\")\n",
    ");\n",
    "print(\"Training Dockerfile path Lambda Updated\")\n",
    "\n",
    "Lambda.update_function_code(\n",
    "    FunctionName=outputs['InferenceDockerfilePathLambda'],\n",
    "    ZipFile=zipString(\"\"\"\n",
    "def handler(event,context):\n",
    "    return \"docker-images/inference\"    \n",
    "\"\"\")\n",
    ");\n",
    "print(\"Inference Dockerfile path Lambda Updated\")\n",
    "\n",
    "#Update lambda with code in a file\n",
    "Lambda.update_function_code(\n",
    "    FunctionName=outputs['TrainingConfigLambda'],\n",
    "    ZipFile=getZip(\"training\")\n",
    ");\n",
    "print(\"Training Config Lambda Updated\")\n",
    "\n",
    "Lambda.update_function_code(\n",
    "    FunctionName=outputs['EndpointConfigLambda'],\n",
    "    ZipFile=getZip(\"endpoint\")\n",
    ");\n",
    "print(\"Endpoint Config Lambda Updated\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploy! <a name=\"Deploy\"></a>\n",
    "The following will \n",
    "- add the CodeCommit repo created by the cloudformation template as a remote named deploy\n",
    "- push example code to repo (will trigger a build)\n",
    "- upload our data to the DataBucket created by the Cloudformation template (will trigger a build)\n",
    "\n",
    "Once a build has started no new build can be started till the first one finishes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#push our Dockerfile code to the \"deploy\" CodeCommit repo\n",
    "run(\"cd aws-sagemaker-build && git remote add deploy {0}; git push deploy master\".format(outputs['RepoUrl']),\n",
    "    stderr=STDOUT,\n",
    "    shell=True) \n",
    "print(\"code Pushed\")\n",
    "\n",
    "#upload the data to the DataBucket\n",
    "object = s3.Object(outputs[\"DataBucket\"],'train/data.csv')\n",
    "object.upload_file(data) \n",
    "print(\"data uploaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also trigger a build by publishing to the launch topic directly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=sns.publish(\n",
    "    TopicArn=outputs['LaunchTopic'],\n",
    "    Message=\"start\" #message is not important, just publishing to topic starts build\n",
    ")\n",
    "print(\"message published\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wait <a name=\"Wait\"></a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use the following code to get a notification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "result=sns.subscribe(\n",
    "    TopicArn=outputs['TrainStatusTopic'],\n",
    "    Protocol=\"SMS\",\n",
    "    Endpoint=\"x-xxx-xxx-xxxx\" #put your phone number here\n",
    ")\n",
    "print(\"subscribed to topic\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the status of StateMachine as it builds and deploys our custom model. We can then setup a some code to wait for our build to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "#list all executions for our StateMachine to get our current running one\n",
    "result=step.list_executions(\n",
    "    stateMachineArn=outputs['StateMachine'],\n",
    "    statusFilter=\"RUNNING\"\n",
    ")['executions']\n",
    "\n",
    "if len(result) > 0:\n",
    "    response = step.describe_execution(\n",
    "        executionArn=result[0]['executionArn']\n",
    "    )\n",
    "    status=response['status']\n",
    "    print(status,response['name'])\n",
    "    #poll status till execution finishes\n",
    "    while status == \"RUNNING\":\n",
    "        print('.',end=\"\")\n",
    "        sleep(5)\n",
    "        status=step.describe_execution(executionArn=result[0]['executionArn'])['status']\n",
    "    print()\n",
    "    print(status)\n",
    "else:\n",
    "    print(\"no running tasks\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use <a name=\"Use\"></a>\n",
    "Next we get some data and send to our newly deployed endpoint!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "test_data=pd.read_csv(data, header=None).sample(10)\n",
    "test_X=test_data.iloc[:,1:]\n",
    "test_y=test_data.iloc[:,0]\n",
    "\n",
    "#convert test_X to csv\n",
    "Body=str.encode(test_X.to_csv(header=False,index=False))\n",
    "\n",
    "result=sagemaker.invoke_endpoint(\n",
    "    EndpointName=outputs['SageMakerEndpoint'],\n",
    "    Body=Body,    \n",
    "    ContentType=\"text/csv\",\n",
    "    Accept=\"text/csv\"\n",
    ")\n",
    "\n",
    "print(pd.read_csv(StringIO(result['Body'].read().decode('utf-8')),header=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion <a name=\"Conclusion\"></a>\n",
    "\n",
    "Hopefully SageBuild can help you develop and deploy SageMaker custom models faster and easier. If you have any problems please lets us none in our github issues [here](). Feel free to send us pull request!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
